{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsxLCRv6YgO2Jq6e2CB1XG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ad5454/SDC-p/blob/main/SDC_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Data"
      ],
      "metadata": {
        "id": "dAphEATYw6qv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qYUATlvcbqW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf50a48-d10b-4de4-a583-7b419ef1ae73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"drive/My Drive/archive.zip\",\"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "IDbKvPmKeGX1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Xtc9iPKgeUXT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Splitting"
      ],
      "metadata": {
        "id": "jj_g81u1xBlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1xfOJfSOUFD",
        "outputId": "efebdfdd-dbe2-4f3a-a659-eff8bfb5e39f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/train', output=\"output2\", seed=1337, ratio=(0.8, 0.1, 0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZpp2I8fOWwy",
        "outputId": "5fe975ea-aa95-49e7-d7c4-066ce72b2621"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 39209 files [00:05, 7778.83 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=\"/content/output2/train\"\n",
        "test_dir=\"/content/output2/test/\""
      ],
      "metadata": {
        "id": "RsRfgAJtOZ0M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Processing"
      ],
      "metadata": {
        "id": "ytd0h_Cuxd-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale the data and create data generator instances\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Load data in from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical') # changed to categorical\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuZtmv9VOdHQ",
        "outputId": "4ebb4f9b-8d0a-4328-8a04-5a7dbf17aa0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31367 images belonging to 43 classes.\n",
            "Found 3922 images belonging to 43 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzoldikxQrHu",
        "outputId": "293cb372-a531-471a-e05a-e6442220aabc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' '1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21'\n",
            " '22' '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35'\n",
            " '36' '37' '38' '39' '4' '40' '41' '42' '5' '6' '7' '8' '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "_2WsH9AFQu7_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline model"
      ],
      "metadata": {
        "id": "1AU6OmI9xnwg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ISdSGzPvEN44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D,Dense"
      ],
      "metadata": {
        "id": "Pp7eS7qiEONJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATING MODEL_04\n",
        "\n",
        "\n",
        "model_04 = Sequential()\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_04.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_04.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_04.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_04.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#FLATTEN LAYER TO MATCH THE SIZE OF THE OUTPUT\n",
        "model_04.add(Flatten())\n",
        "\n",
        "model_04.add(Dense(256, activation='relu'))\n",
        "\n",
        "#OUTPUT LAYER\n",
        "model_04.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#COMPILE THE MODEL_04\n",
        "\n",
        "model_04.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "#FITTING THE MODEL_04\n",
        "\n",
        "history_04 = model_04.fit(train_data, \n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brXRCx3vxpsp",
        "outputId": "051e9f91-b16d-44fc-88c0-f4e7d95a9db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "981/981 [==============================] - 150s 133ms/step - loss: 0.8982 - accuracy: 0.7535 - val_loss: 0.1736 - val_accuracy: 0.9495\n",
            "Epoch 2/5\n",
            "923/981 [===========================>..] - ETA: 7s - loss: 0.0983 - accuracy: 0.9707"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NEXT MODEL"
      ],
      "metadata": {
        "id": "AjzAb3nDyHaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D,Dense"
      ],
      "metadata": {
        "id": "iekb0D_aQx2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATING MODEL_05\n",
        "\n",
        "\n",
        "model_05 = Sequential()\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_05.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_05.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_05.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#CONVOLUTIONAL LAYER\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "model_05.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "\n",
        "#MAXPOOLING LAYER\n",
        "model_05.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#FLATTEN LAYER TO MATCH THE SIZE OF THE OUTPUT\n",
        "model_05.add(Flatten())\n",
        "\n",
        "model_05.add(Dense(256, activation='relu'))\n",
        "\n",
        "#OUTPUT LAYER\n",
        "model_05.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#COMPILE THE MODEL_05\n",
        "\n",
        "model_05.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "#FITTING THE MODEL_05\n",
        "\n",
        "history_05 = model_05.fit(train_data, \n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "jNZlkT_yl0F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_05.evaluate(test_data)"
      ],
      "metadata": {
        "id": "grxyvCl9o7V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_05)"
      ],
      "metadata": {
        "id": "PnBjm-LypCR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTIONS"
      ],
      "metadata": {
        "id": "0BzhCEQKygYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor\n",
        "  and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "  \"\"\"\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels \n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img"
      ],
      "metadata": {
        "id": "b1WecMAEp3K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust function to work with multi-class\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "     "
      ],
      "metadata": {
        "id": "trAk-2DPqFWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names for our multi-class dataset\n",
        "import pathlib\n",
        "import numpy as np\n",
        "# Label Overview\n",
        "classes = [ 'Speed limit (20km/h)',\n",
        "            'Speed limit (30km/h)', \n",
        "            'Speed limit (50km/h)', \n",
        "            'Speed limit (60km/h)', \n",
        "            'Speed limit (70km/h)', \n",
        "            'Speed limit (80km/h)', \n",
        "            'End of speed limit (80km/h)', \n",
        "            'Speed limit (100km/h)', \n",
        "            'Speed limit (120km/h)', \n",
        "            'No passing', \n",
        "            'No passing veh over 3.5 tons', \n",
        "            'Right-of-way at intersection', \n",
        "            'Priority road', \n",
        "            'Yield', \n",
        "            'Stop', \n",
        "            'No vehicles', \n",
        "            'Veh > 3.5 tons prohibited', \n",
        "            'No entry', \n",
        "            'General caution', \n",
        "            'Dangerous curve left', \n",
        "            'Dangerous curve right', \n",
        "            'Double curve', \n",
        "            'Bumpy road', \n",
        "            'Slippery road', \n",
        "            'Road narrows on the right', \n",
        "            'Road work', \n",
        "            'Traffic signals', \n",
        "            'Pedestrians', \n",
        "            'Children crossing', \n",
        "            'Bicycles crossing', \n",
        "            'Beware of ice/snow',\n",
        "            'Wild animals crossing', \n",
        "            'End speed + passing limits', \n",
        "            'Turn right ahead', \n",
        "            'Turn left ahead', \n",
        "            'Ahead only', \n",
        "            'Go straight or right', \n",
        "            'Go straight or left', \n",
        "            'Keep right', \n",
        "            'Keep left', \n",
        "            'Roundabout mandatory', \n",
        "            'End of no passing', \n",
        "            'End no passing veh > 3.5 tons' ]\n"
      ],
      "metadata": {
        "id": "94ote-EkqIck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names for our multi-class dataset\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "xyf9WgA0rb4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust function to work with multi-class\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "  \n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {classes[int(pred_class)]}\")\n",
        "  # plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n"
      ],
      "metadata": {
        "id": "zXvn9FWGrcei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using efficienet_2_model\n",
        "pred_and_plot(model=model_05, \n",
        "              filename=\"/content/test/00011.png\", \n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "a3yiUxDAqMN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}